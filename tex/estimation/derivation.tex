% Copyright © 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Deriving point estimators}%
\addcontentsline{toc}{part}{Overview of point estimation}

\section{Summarizing data sets}

\begin{itemize}

\item We'll start with a few very basic definitions.
  \begin{defn}
    The random variables $X₁,...,X_n$ are a \emph{random sample} if
    they form an i.i.d. draw from some distribution $F$.
  \end{defn}

  \begin{defn}
    If $T$ is a function from the sample space of $(X₁,...,X_n)$ to
    $\RR^k$ then the random variable $T(X₁,...,X_n)$ is a
    \emph{statistic}.
  \end{defn}

  Note that statistics are random variables and have distributions.  A
  statistic is anything that can be calculated from the data.  It can
  not depend on unknown parameters of the distribution.

\item It's worth spending a little while thinking about ``reasonable''
  ways to summarize datasets.  For now, we're only going to worry
  about mathematical characterizations of ``summarizing'' a dataset,
  we're not going to get into statistical graphics, etc.  One natural
  way to think about a data summary is through the idea of
  ``sufficient'' statistics.

  \begin{defn}
    If $X₁,...,X_n ∼ f(·; θ)$ is a draw from a known family of
    distributions with unknown parameter $θ$, a statistic $T(X)$ is a
    \emph{sufficient statistic for $θ$} if the conditional
    density/distribution $f(· ∣ T(X))$ does not depend on $θ$.
  \end{defn}

  The order statistics are always going to be a sufficient statistic
  for i.i.d. random variables, but there are often better (as in
  smaller) options, and we'll present a result soon that can help in
  constructing sufficient statistics.

  \begin{defn}
    $T(X)$ is a \emph{minimal sufficient statistic} if it is a
    function of any other sufficient statistic.
  \end{defn}

  First, though, there's the related concept of ancillarity.

  \begin{defn}
    If $X₁,...,X_n ∼ f(·; θ)$ is a draw from a known family of
    distributions with unknown parameter $θ$, a statistic $T(X)$ is an
    \emph{ancillary statistic for $θ$} if the sampling distribution of
    $T(X)$ does not depend on $θ$.
  \end{defn}

\item The ``factorization theorem'' is useful in determining whether
  or not a given statistic is sufficient for a parameter.
  \begin{thm}
    If $f(x; θ)$ is the joint pdf of $(X₁,...,X_n)$, $T(X)$ is a
    sufficient statistic for $θ$ if and only if
    \begin{equation*}
      f(x; θ) = g(T(x); θ) h(x)
    \end{equation*}
    for some functions $g$ and $h$.
  \end{thm}
  The important thing to note is that $T(x)$ and $θ$ are both in $g$
  and $θ$ is not in $h$.  The other thing to note is the ``if and only
  if'' part of the proof.

  It is straightforward to prove that sufficiency implies the
  factorization holds: let $h(x)$ be the joint density of $x$ given
  $T(X)$.  It is less straightforward, but more important in practice,
  to prove that existence of the factorization implies sufficiency.
  The result still follows from the conditional densities (as it seems
  that it must).
  \begin{align*}
    f_X(x ∣ T(X) = T(x); θ)
    &= f(x, T(x); θ) / f_T(T(x); θ) \\
    &= f_X(x; θ) / f_T(T(x); θ) \\
    &= g(T(x); θ) h(x) / f_T(T(x); θ)
  \end{align*}
  where the second equality holds because $T(x)$ is redundant when we
  know $x$, and the third equality holds because we're assuming that
  this factorization exists.

  Now we can write the denominator as
  \begin{align*}
    f_T(T(x); θ)
    &= ∫_A f(T(y) ∣ X = y; θ) f_X(y) dy \\
    &= ∫_A f_X(y; θ) dy \\
    &= ∫_A g(T(x); θ) h(y) dy \\
    &= g(T(x); θ) ∫_A h(y) dy
  \end{align*}
  where $A$ is the set of points s.t. $T(y) = T(x)$ for all $y ∈ A$
  and the equalities hold for the same reasons as before.

  Now just merge the two equations to get
  \begin{equation*}
    f_X(x ∣ T(X) = T(x); θ)
    = \frac{g(T(x); θ) h(x)}{g(T(x); θ) ∫_A h(y) dy}
    = \frac{h(x)}{∫_A h(y) dy}.
  \end{equation*}
  This last quantity does not depend on $θ$, so we're done.

  We can use the factorization thoerem to prove that $\min_i X_i$ and
  $\max_i X_i$ are sufficient statistics for the uniform$(a,b)$.
  \begin{ex}
    The joint pdf of $X₁,...,X_n$ is
    \begin{align*}
      f(x₁,...,x_n; a, b)
      &= ∏_{i=1}^n \tfrac{1}{b-a} \1\{x_i ∈ [a,b]\} \\
      &= \Big(\tfrac{1}{b-a}\Big)^n \1\{a ≤ \min_i x_i \& \max_i x_i ≤ b\},
    \end{align*}
    so we can define $h(x) = 1$ and
    \begin{equation*}
      g(T(x); a, b) = \Big(\tfrac{1}{b-a}\Big)^n \1\{a ≤ \min_i x_i \& \max_i x_i ≤ b\}.
    \end{equation*}
  \end{ex}

\item We can also think of the density function itself as giving a
  summary of the dataset.\sidenote{Note that we're implicitly assuming
    that we know the density function, but that's not really true.}
  Earlier, though, we viewed the densities as functions of the
  possible values of the random variables, $x$, given particular
  parameter values.  Now we're going to treat the random variables as
  known/observed and view the densities as functions of the possible
  parametrizations.  When we do that, we call them \emph{likelihoods}
  and will typically write them as $L(θ; x)$.

  [PLOT PICTURE OF UNIFORM LIKELIHOOD.]

  Regions where the likelihood is high are to some degree more
  plausible than regions where it is low.  If we look at the uniform
  dist; when the likelihood is higher, its corresponding density is
  more concentrated around the observed data.

\end{itemize}

\section{Method of Moments}
I'd like to add a form of loss-function minimization after the Method
of Moments section.
\begin{itemize}
\item Suppose we have $X₁,…,X_n ∼ f(x; θ)$
\begin{itemize}
\item $f$ is known
\item $θ$ is an unknown $p$-vector that we want to estimate
\end{itemize}
\item estimator is based on a simple idea:
  \begin{itemize}
  \item if we want to estimate an expectation, use a sample average
  \item $\Pr[X_i ≤ c]$ for known $c$
    \begin{itemize}
    \item $=\E \1\{X_i ≤ x\}$
    \item estimate with $n^{-1} ∑_{i=1}^n 1\{X_i ≤ c\}$
    \end{itemize}
  \item Estimate $\E X_i$ with $n^{-1} ∑_{i=1}^n X_i$
  \item etc
  \end{itemize}
\item in general, relate $θ$ to the population moments:
  \begin{itemize}
  \item if $θ$ has $p$ elements, we calculate the first $p$ moments of $X_i$
    \begin{align*}
    μ₁  &= g₁(θ), &
    μ₂  &= g₂(θ), &
    & \dots &
    μ_p &= g_p(θ),
    \end{align*}
  \end{itemize}
\item calculate the sample moments:
  \begin{align*}
    \μh₁ &= \ov{n} ∑_{i=1}^n X_i, &
    \μh₂ &= \ov{n} ∑_{i=1}^n X_i², &
    & \dots &
    \μh_p &= \ov{n} ∑_{i=1}^n X_i^p,
  \end{align*}
\item estimate $θ$ by setting the equations equal:
  \begin{equation*}
    (g₁(\θh),…, g_p(\θh)) =  (\μh₁,…, \μh_p) = 
    \Big( \ov{n} ∑_{i=1} X_i,…,\ov{n} ∑_{i=1} X_i^p \Big).
  \end{equation*}
  And then \[\θh = g^{-1} (n^{-1} ∑_{i=1}^n X_i,…,n^{-1} ∑ X_i^p).\]
  Obviously, $g$ needs to be inevitable for this to work.
\item Sometimes $\θh$ is easy to write out analytically as a function
  of the sample averages
  \begin{itemize}
  \item when it's not, you can find $\θh$ numerically.
  \end{itemize}
\item if each sample moment is close to the population moment and
  $g^{-1}$ is continuous, then $\θh$ should be close to $θ$.
\end{itemize}

\section{Examples}

\begin{itemize}
\item normal$(μ,σ²)$
  \begin{itemize}
  \item first moment of a normal random variable is $\E X_i = μ$
  \item second moment is $\E X_i² = σ² + μ²$
  \item method of moments estimator is
    \begin{itemize}
    \item $\μh = \ov{n} ∑_i X_i$
    \item $\σh² = \ov{n} ∑_i X_i² - (n^{-1}∑_i X_i)²
      = \ov{n} ∑_i(X_i - \Xb)²$
    \item which is not the usual estimator, but is close.
    \end{itemize}
  \end{itemize}
\item uniform($a$,$b$)
  \begin{itemize}
  \item Let's say that $X₁,…,X_n$ are iid uniform$(a,b)$, and we want
    to calculate the method of moments estimator for $a$ and $b$.
    \begin{itemize}
    \item density of $X_i$ is $1/(b-a)$ in $[a,b]$, zero otherwise.
    \end{itemize}
  \item Calculate the first two moments:
    \begin{itemize}
    \item $\E X_i = ∫_a^b x /(b-a) dx = \frac{b+a}{2}$
    \item $\E X_i² = ∫_a^b x² /(b-a) dx = \frac{b^3 - a^3}{3(b - a)}
      = \frac{b + ab + a²}{3}$
    \end{itemize}
  \item Gives the estimators:
    \begin{itemize}
    \item $\hat b+\hat a = 2 n^{-1} ∑_i X_i$
    \item $\frac{\hat b³-\hat a³}{\hat b- \hat a} = 3 n^{-1} ∑_i X_i²$
    \item solve for $\hat b$ and $\hat a$, gives
      \begin{itemize}
      \item $\hat b = \Xb + s \sqrt{3}$
      \item $\hat a = \Xb - s \sqrt{3}$
      \item $s = \sqrt{n^{-1} ∑_i (X_i - \Xb)²}$
      \end{itemize}
    \end{itemize}
  \end{itemize}
\item linear regression
  \begin{itemize}
  \item setup
    \begin{itemize}
    \item $(Y_i, X_i) ∼$ i.i.d.
    \item $X_i ∼ f$ (unspecified)
    \item $Y_i ∣ X_i ∼ N(β₀ + β₁ X_i, σ²)$
    \item want to estimate $β₀$ and $β₁$
    \item draw scatterplot (this is like estimating the slope and
      intercept)
    \item We'll often see this as $Y_i = β₀ + β₁ X_i + e_i$
      \begin{itemize}
      \item $e_i ∣ X_i ∼ N(0, σ²)$
      \item i.e. define $e_i = Y_i - β₀ - β₁ X_i$
      \end{itemize}
    \end{itemize}
  \item MoM estimator
    \begin{itemize}
    \item we know $\E \binom{Y_i}{X_i Y_i} =
      \begin{pmatrix} β₀ + β₁ \E X_i \\ β₀ \E X_i + β₁ \E X_i² \end{pmatrix}$
      \begin{itemize}
      \item $= \begin{pmatrix}
          1 & \E X_i \\ 
          \E X_i & \E X_i² \end{pmatrix} \begin{pmatrix}β₀ \\
          β₁
        \end{pmatrix}$
      \end{itemize}
    \item Assuming inevitability, $\begin{pmatrix}β₀\\β₁\end{pmatrix}
      = \begin{pmatrix}1& \E X_i \\ \E X_i & \E X_i²\end{pmatrix}^{-1}
      \begin{pmatrix} \E Y_i \\ \E X_iY_i\end{pmatrix}$
    \item This makes our estimator,
      $\begin{pmatrix}
        \βh₀ \\ \βh₁
      \end{pmatrix}
      =
      \begin{pmatrix} 
        1 & ∑_i x_i/n \\ ∑_i x_i/n & ∑_ix_i²/n 
      \end{pmatrix}^{-1}
      \begin{pmatrix}
        ∑_iy_i/n \\ ∑_ix_iy_i / n
      \end{pmatrix}$
      \begin{itemize}
      \item $=
        \begin{pmatrix}
          1 & ∑_i x_i \\ ∑_i x_i & ∑_i x_i²
        \end{pmatrix}^{-1}
        \begin{pmatrix}
          ∑_i y_i \\ ∑_i x_i y_i
        \end{pmatrix}$
      \item (write in matrix notation and explain)
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{itemize}

\subsection{Discussion}

\begin{itemize}
\item advantages
  \begin{itemize}
  \item it gets you an estimator
  \item easy to derive asymptotic properties of the estimator (it's a
    function of averages, which usually obey CLTs and LLNs).
  \end{itemize}
\item disadvantages
  \begin{itemize}
  \item can be very inefficient
  \item for it to be useful, requires that the moments tell you a lot
    about the distribution (for the uniform, they don't
    necessarily—we're trying to estimate the endpoints, but our
    estimator is to look for the center and double it.)
    \begin{itemize}
    \item a big problem with our estimates here, is we might have $X$s
      in our data that are outside the interval $[a,b]$
    \end{itemize}
  \item kind of ad hoc.
  \item for the uniform distribution, we have \emph{all} of the
    moments defined… should we calculate the first $p$ moments and
    average all of them?
    \begin{itemize}
    \item how do we pick $p$?
    \item are some moments better than others?
    \end{itemize}
  \end{itemize}
\end{itemize}

\subsection{GMM}

\begin{itemize}
\item Hansen (1982) shows that a modification of the method of moments
  can be very useful in macro:
  \begin{itemize}
  \item have periods $t=1,…,T$
  \item macro models tell you that $\E_t g(X_t, θ) = 0$ where $g(x_t,
    θ)$ is coming from Euler equations (ie, an agent is optimizing in
    period $t$, and $g$ captures the difference between what they
    expect to happen in period $t+1$ and what actually happens in
    period $t+1$ -- under rationality, they choose an action that
    makes that difference unpredictable.
  \item LIE tells you that $\E g(X_t, θ) = \E \E_t g(X_t,θ)$ which
    equals zero, so you have the condition
    \[\E g(X_t, θ) = 0\]
  \item Hansen shows that you can often estimate $θ$ by solving
    \[ T^{-1} ∑_{t=1}^T g(X_t,θ) = 0 \]
    for $θ$. (and says how)
  \item when you have more moments than parameters, gives a weighting
    scheme.
  \end{itemize}
\end{itemize}

\section{Loss-function minimization}

Add!

\section{Introduction to Maximum Likelihood Estimation}

\begin{itemize}
\item look at the uniform$(0,b)$ example suppose $n = 1$
  \begin{itemize}
  \item draw these densities for $b$ = 1, 2, 4
    \begin{itemize}
    \item density is $1/b$ in $[0,b]$.
    \item pick a point $x$ on the density
    \end{itemize}
  \item have (as a function of $b$) $1/b$ as long as $b ≥ x$
  \item if we observe $X = 0.5$ (for example), we know that $b ≥ 0.5$
  \item In addition, values like $b = 500$ are implausible
    \begin{itemize}
    \item as $b$ gets larger, there are more possible values that $X$ is
      likely to take on.
    \end{itemize}
  \item in a sense, $b = 0.5$ is the most plausible
    \begin{itemize}
    \item smaller values are impossible
    \item as $b$ increases from $0.5$, the plausibility decreases.
    \end{itemize}
  \item we can get $b = 0.5$ directly by maximizing $f(0.5; b)$ as a
    function of $b$
    \begin{itemize}
    \item called the likelihood and written $L(b; x)$
    \end{itemize}
  \end{itemize}
\end{itemize}

\section{Definition}

\begin{itemize}
\item for the MLE estimator, we start with the density, but view it as
  a function of $θ$
  \begin{itemize}
  \item the value of $θ$ that maximizes the likelihood is (in a sense)
    the most plausible/defensible value.
  \end{itemize}
\item the MLE of $θ$ is $\argmax_θ L(θ; x₁,…,x_n)$
\end{itemize}

\section{Examples}

\subsection{iid draws from uniform$(a,b)$}
\begin{itemize}
\item $L(a,b; x₁,…,x_n) = ∏_i 1\{x_i ∈ [a,b]\} (b-a)^{-1}$
\item $= ({1 \over b-a})^{n}$ if all $x_i ∈ [a,b]$ and zero otherwise.
\item we can find the maximum easily
  \begin{itemize}
  \item likelihood decreases as $b$ increases or $a$ decreases
  \item likelihood becomes zero if $b < \max x_i$ or if $a > \min x_i$
  \item so $\hat b = \max x_i$ and $\hat a = \min x_i$
  \end{itemize}
\end{itemize}

\subsection{linear regression.}
\begin{itemize}
\item $(Y_i,X_i) ∼ iid$
  \begin{itemize}
  \item $X_i ∼ f$ which is unspecified, $X_i$ is a $k × 1$ vector.
  \item $Y_i ∣ X_i ∼ N(X_i'β, σ²)$
  \end{itemize}
\item want to estimate $β$ and $σ²$
\item Draw fitted values, densities
\item $L(μ,σ²; y, x) = ∏_i {1 \over \sqrt{2 π σ²}}
  e^{- {(y_i - x_i'β)² \over 2 σ²}} f(x_i)$
\item step 1: take logs:
  \begin{itemize}
  \item $\log L(μ,σ²; x₁,…,x_n) = const - n\log (\sqrt{σ²}) -
    ∑_i {(x_i - μ)² \over 2 σ²} + ∑_i f(x_i)$
  \end{itemize}
\item First order conditions:
  \begin{itemize}
  \item for mean:
    \begin{itemize}
    \item $\frac{\partial}{\partial β} \log L(μ, σ²; x, y) = ∑_{i=1}^n x_i (y_i - x_i'β) = 0$
    \item so $\βh=(∑_i x_i x_i')^{-1} ∑_i x_i y_i$
    \end{itemize}
  \item for variance:
    \begin{itemize}
    \item $\frac{\partial}{\partial σ²} \log L(μ, σ²; x, y) = -\frac{n}{2σ²} + \frac{1}{2 σ^4}∑_i (y_i - x_i'β)² = 0$
    \item so $\hat σ² = \frac{1}{n} ∑_{i=1}^n (y_i - x_i'β)²$
    \end{itemize}
  \end{itemize}
\item students should verify that this is a maximum on their own.
\end{itemize}

\section{More remarks on mle}

\begin{itemize}
\item unlike method of moments, where we connect our parameters to the
  mean, variance, etc. regardless of the distribution; here we look at
  the features of the data that the distribution tells us are the most
  relevant.
  \begin{itemize}
  \item for normal, this \emph{is} the mean and variance, so MLE and
    MoM give us the same statistics
  \item for uniform, and others, this is \emph{not} the mean and
    variance.  - the derivative of the log likelihood is called the
    \emph{score}.  
    $S(θ; x) = {\partial \over \partial θ} \log L(θ; x)$
  \end{itemize}
\item has a nice invariance property: say you're not interested in the
  parameters per se, but care about a transformation of the parameters
  $T(θ)$.  If $\θh$ is the maximum likelihood estimator of $θ$,
  then $T(\θh)$ is the MLE of $T(θ)$.
\item we'll see later that you can use MLE to get an estimator, even
  if you don't believe that the distribution is true
  \begin{itemize}
  \item called quasi-maximum likelihood
  \item obviously, you then need to check that the estimator works well.
  \end{itemize}
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../estimation"
%%% End: 

%  LocalWords:  datasets dataset
