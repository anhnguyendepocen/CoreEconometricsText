% Copyright © 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Random variables, distributions, and densities}%
\addcontentsline{toc}{part}{Random variables, distributions, and densities}

\section{Random variables as we might wish to introduce them to
  undergraduates.}

\begin{itemize}

\item We're trying to capture the idea of a ``hypothetical'' number
  that might take on many different values.  For example, if I were to
  go to Las Vegas next weekend, I might win \$10 while I'm there; I
  might win \$1,000; I might ``win'' --\$5,000; etc.  If we're going
  to talk meaningfully about what might happen if I go to Las Vegas,
  we're going to need a way to match each outcome (here how much money
  I win or lose) with the relative frequency of that outcome.

  The simplest\sidenote{``Simplest'' from a conceptual/intuitive
    standpoint; we'll see that this is far from the simplest way from
    a rigorous mathematical standpoint.}  way to do this is through a
  probability density function and, as in most of probability, the
  easiest way to start is to work with discrete events (in which case
  the ``density'' function us usually called a ``probability mass
  function'').  Suppose that we're interested in a countable number of
  possible outcomes on the real line; think of handful of dice and
  adding up all of the numbers, so the possible values that the sum
  can take on are in some set $S = \{x_i ∣ i ∈ \ZZ\}$, where \ZZ\ is
  the set of integers.  Then we can define a probability density
  function $f: \RR → \RR$ as the function such that
  \begin{enumerate}
  \item $f(x) ≥ 0$ for all $x ∈ \RR$,
  \item $f(x) = 0$ for all $x ∉ S$, and
  \item $∑_{x ∈ S} f(x_i) = 1$.
  \end{enumerate}

  So now we can think of a random variable $X$ that takes on values in
  the set $\mathcal{X}$ with probabilities given by $f$.  And we can
  build a probability function from a density $f$ for the random
  variable $X$ by asserting that, for any $A ⊂ S$,
  \begin{equation*}
    \Pr[ X ∈ A ] = ∑_{s ∈ A} f(s)
  \end{equation*}

\item If we want to let $X$ take on the entire range of values in \RR\
  we can proceed the same way.  Again define the density function $f:
  \RR → \RR$ such that
  \begin{enumerate}
  \item $f(x) ≥ 0$ for all $x ∈ \RR$ and
  \item $∫_{-∞}^∞ f(x) dx = 1$.
  \end{enumerate}
  We can again build a probability function from the density function.
  For any closed interval $[a, b]$,\sidenote{Remember, $[a,b] = \{x ∈
    \RR ∣ a ≤ x ≤ b\}$.} we can define
  \begin{equation*}
    \Pr[ X ∈ [a,b] ] = ∫_a^b f(x) dx,
  \end{equation*}
  and for any set $A$ that can be written as the union of a countable
  number of disjoint intervals, $A = ⋃_i [a_i, b_i]$, where $⋂_i [a_i,
  b_i] = ∅$, we can define
  \begin{equation*}
    \Pr[ X ∈ A ] = ∑_i \Pr[ X ∈ [a_i, b_i] ] = ∑_i ∫_{a_i}^{b_i} f(x) dx
  \end{equation*}

\item It's natural to want to go even further, and define for any set
  $A ⊂ \RR$
  \begin{equation*}
    \Pr[ X ∈ A ] = ∫_A f(x) dx ≡ ∫_{-∞}^∞ \1\{x ∈ A\} f(x) dx,
  \end{equation*}
  but it turns out that this integral is not well-defined for every $A
  ⊂ \RR$ (and, consequently, it's possible to construct functions $f$
  that can't be used as densities, a fact that we glossed over
  earlier).  However, it should be obvious that we can construct a
  self-contained set of subsets of \RR, call it \BB, so that we can
  define $\Pr[X ∈ B] = ∫_B f(x) dx$ for all $B ∈ \BB$.

  We can motivate some of properties that \BB\ needs from properties
  that seem necessary for the probability function $\Pr$.

  \begin{enumerate}
  \item We need $\Pr[X ∈ \RR] = ∫_{-∞}^∞ f(x) dx = 1$, so \RR\ must be
    in \BB.
  \item If $\Pr[X ∈ B]$ is well defined then $\Pr[X ∉ B]$ should be as
    well, and we should have $\Pr[X ∉ B] = 1 - \Pr[X ∈ B]$.  Since $X
    ∉ B$ is equivalent to $X ∈ B^c$, $B^c$ must be in \BB\ whenever
    $B$ is.
  \item If $B₁$, $B₂$, $B₃$,... make up a countable sequence of sets and
    we can define $\Pr[X ∈ B_i]$ for each of them, we should be able
    to define $\Pr[X ∈ ⋃_i B_i]$ and $\Pr[X ∈ ⋂_i B_i]$.  So \BB\ must
    be closed under countable unions and intersections.
  \end{enumerate}

  Any set of sets \BB\ that satisfies those three properties is called
  a \emph{sigma-algebra} (or \emph{σ-algebra}).  For subsets of the
  real line, there's an especially useful and common σ-algebra, the
  \emph{Borel σ-algebra},which is defined as the smallest σ-algebra
  that has all of the intervals as elements.

\item The integral we're interested is a little different than the
  usual Riemann integral that you've seen in introductory calculus
  classes, but not in any way that's going to matter for our purposes.
  The key difference is that it works by taking different points in
  the function's height and mapping them back to Borel sets in the
  function's domain, while the Riemann integral works by taking
  different points in the function's domain and mapping them to the
  height.\sidenote{Remember, to get the Riemann integral of a function
    $g: \RR → \RR$ over $[a,b]$, first define an increasingly fine
    partition of $[a,b]$, $\{x_{i,n}, i = 1,…n, n = 1,2,…\}$ such that
    $a = x_{1,n}$, $b = x_{n,n}$, $x_{i,n} < x_{i+1,n}$ for all $i$
    and $\max_{i=1,…,n-1} |x_{i+1,n} - x_{i,n}| → 0$ as $n → ∞$.  If
    we let $M_i = \max_{x ∈ [x_{i,n}, x_{i+1,n}]} g(x)$ and $m_i =
    \min_{x ∈ [x_{i,n}, x_{i+1,n}]} g(x)$, then the Riemann integral
    exists if
    \begin{multline*}
      \lim_{n → ∞} ∑_{i=1}^{n-1} M_i (x_{i+1,n} - x_{i,n}) \\
      = \lim_{n → ∞} ∑_{i=1}^{n-1} m_i (x_{i+1,n} - x_{i,n})
    \end{multline*}
    for any partition $\{x_{n,i}\}$.} 
  So, if $g$ is any step function that can be written as a step
  function of Borel sets,
  \begin{equation*}
    g(x) = ∑_{i=1}^∞ c_i \1\{x ∈ B_i\}
  \end{equation*}
  where $B_i ∈ \BB$, we can define the Lebesgue integral as
  \begin{equation*}
    ∫ g dμ = ∑_{i=1}^∞ c_i μ(B_i),
  \end{equation*}
  where $μ(B_i)$ is the length of the set $B_i$.\sidenote{I should
    maybe add a definition or an Appendix on Lebesgue measure, but
    that will probably happen later.}  The integrals of functions that
  are not step functions can be evaluated as the limit of a sequence
  of integrals of functions that are step functions.  For example, if
  $g_n → f$ as $n → ∞$ where each $g_n = ∑_i c_{i,n} \1\{x ∈ B_{i,n}\}$
  then we often can show that
  $∫ f dμ = \lim_{n → ∞} ∑_i c_{i,n} μ(B_{i,n})$ (I say ``often''
  because there are some conditions on the sequence $\{g_n\}$ that we
  haven't mentioned that need to be satisfied for this to hold)

  For all of this to work, we need to be able to find a Borel set in
  the domain of the function for any set of points in the range;
  i.e. for the step function above, we have, for any point $x$,
  \begin{equation*}
    g^{-1}(\{x\}) =
    \begin{cases}
      B_i & x = c_i \\
      ∅ & x ∉ \{c₁, c₂,…\}
    \end{cases}
  \end{equation*}
  and, for any $B ∈ \BB$, $g^{-1}(B) = ⋃_{i ∈ I} B_i$ where $I = \{i ∣
  c_i ∈ B\}$.\sidenote{You should prove on your own that this means
    that $\{g^{-1}(B) ∣ B ∈ \BB\}$ is a σ-algebra and is a subset of
    \BB.}

\item The key proprerty, then, for this integral to work is that
  $g^{-1}(\BB)$ itself be a σ-algebra that is contained in \BB.  Such
  a function is called \emph{Borel-measurable}.  We're going to
  restrict our focus to densities $f$ that are Lebesgue measurable, so
  we can always write probabilities as
  \begin{equation*}
    \Pr[X ∈ B] = ∫_B f(x) dx
  \end{equation*}
  for Borel-sets $B$.  We won't be able to define these probabilities
  for non-Borel sets, but that's fine; in this case, every function
  that we'd want to work with is Lebesgue-measurable and every set
  that we'd want to work with is a Borel set.\sidenote{Add example of
    unmeasurable set here....}

  If we're clever, we can define probabilities for discrete random
  variables the same way.  Define the function $δ$, known as Dirac's
  δ-function, as $δ = \lim_{n → ∞} δ_n$ where
  \begin{equation*}
    δ_n(x) =
    \begin{cases}
      n + n² x & - \tfrac{1}{n} ≤ x ≤ 0 \\
      n - n² x & 0 < x ≤ \tfrac{1}{n} \\
      0        & \text{otherwise},
    \end{cases}
  \end{equation*}
  so each $δ_n$ is a very narrow, very tall spike at 0 with total area
  1, and as $n$ grows the spike gets narrower and higher.  The limit
  $δ$ is an infinitely tall, infinitely narrow spike at 0 with total
  area 1.

  Under Lebesgue-measure, we can now define the density of a
  Bernoulli(1/2) random variable $b$ as
  \begin{equation*}
    f_b(x) = \tfrac{1}{2} δ(x) + \tfrac{1}{2} δ(x - 1).
  \end{equation*}
  This lets us write $\Pr[b ∈ B] = ∫_B f_b(x) dx$ for any Borel-set
  $B$, which is what we want.\sidenote{You should work through all of
    the steps necessary to prove this to yourself.}

\item Two key points to emphasize and remember: if the usual Riemann
  integral of a function exists, its value is the same as the Lebesgue
  integral. And it is very difficult to accidentally write down a
  function on \RRⁿ\ that is not Lebesgue measurable, so don't worry
  that you will.

\item The probabilities for a given random variable $X$ can be
  summarized by its \emph{cumulative distribution function} (CDF)
  which is typically written as $F_X$ and is defined as
  \begin{equation*}
    F_x(c) ≡ \Pr[X ≤ c] = \Pr[X ∈ (∞, c]]
  \end{equation*}
  for any $c ∈ \RR$.  The CDF of a random variable always exists and
  satisfies
  \begin{enumerate}
  \item $\lim_{x → -∞} F_X(x) = 0$
  \item $\lim_{x → ∞} F_X(x) = 1$
  \item $F_X$ is non-decreasing in $x$.
  \item $F_X$ is right-continuous.  For every number $x₀$,
    $\lim_{x ↓ x₀} F(x) = F(x₀)$.
  \end{enumerate}

  You should verify the property $\Pr[X ∈ (a, b]] = F_X(b) - F_X(a)$
  as homework.

\item (Misc. definition that needs to go somewhere) The \emph{support}
  of a random variable is the set of points where its density is
  positve: $\{x ∈ \RR ∣ f_X(x) > 0\}$

\end{itemize}

\section{Sigma-algebras as information sets}

\begin{itemize}

\item In the previous section, we motivated the Borel σ-algebra as a
  collection of sets that it makes sense to assign length to, and that
  it makes sense to talk about the ``Probability'' of a random
  variable landing in.  As you've probably seen elsewhere, we should
  think of a random variable is a way of numerically summarizing a
  random outcome.

\item Sometimes it doesn't make sense to assign numeric values right
  away, though.  If we want to think about modeling card games, the
  events that we might be concerned with are different hands that we
  might be dealt.  But it might not make sense to summarize that
  information numerically unless we have already set a particular
  game.  Fortunately, the key properties that we were discussing
  beforehand don't need to be specific to numbers.

  In general, we can call the set of all possible outcomes of a
  (possibly hypothetical) experiment the \emph{sample space} of the
  experiment, and let $Ω$ be the \emph{σ-algebra} of the experiment if
  it satisfies the rules we discussed above.  The elements of $Ω$ are
  usually refered to as \emph{events}.

  Since set theory plays a large role in this material,
  Table~\ref{tab:1} lists the definitions of common set operations.

\begin{table*}[h]
\begin{tabular}{lp{4in}}
  \toprule
  \multicolumn{2}{c}{Finite Set Operations} \\
  \midrule
  Union        & $A₁ ∪ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ or } x∈ A₂\}$ \\
  Intersection & $A₁ ∩ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ and } x ∈ A₂\}$ \\
  Subset       & $A₁ ⊂ A₂$ if $A₁ ∩ A₂ = A₁$ \\
  Equality     & $A₁ = A₂$ if $A₁ ⊂ A₂$ and $A₂ ⊂ A₁$ \\
  Complement   & $A₁^c ≡ \{x ∈ S : x ∉ A₁\}$ \\
  Difference   & $A₁ ∖ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ and } x ∉ A₂\}$ \\
  Symmetric difference & $A₁ Δ A₂ ≡ (A₁ ∖ A₂) ∪ (A₂ ∖ A₁)$ \\
  \midrule
  \multicolumn{2}{c}{Infinite Set Operations (can be defined for uncountable index sets as well)} \\
  \midrule
  Union        & $⋃_{k=1}^∞ A_k ≡ \{x ∈ S : x ∈ A_k$ for at least one $k ∈ 1,2,...\}$ \\
  Intersection & $⋂_{k=1}^∞ A_k ≡ \{x ∈ S : x ∈ A_k$ for all $k ∈ 1,2,...\}$ \\
  Infimum      & $\inf_{k ≥ n} A_k ≡ ⋂_{k=n}∞ A_k$ \\
  Supremum     & $\sup_{k ≥ n} A_k ≡ ⋃_{k=n}^∞ A_k$ \\
  lim inf      & $\liminf_{n → ∞} A_n ≡ ⋃_{n=1}^∞ ⋂_{k=n}^∞ A_k$ \\
  lim sup      & $\limsup_{n → ∞} A_n ≡ ⋂_{n=1}^∞ ⋃_{k=n}^∞ A_k$ \\
  \midrule
  \multicolumn{2}{c}{Other definitions} \\
  \midrule
  limit 
  & Suppose that $A$, $A₁$, $A₂$,... is a sequence of subsets of $S$ and that $\limsup_{n → ∞} A_n = \liminf_{n → ∞} A_n = A$.
  Then $A$ is the limit of $\{A_n\}$. \\
  Disjoint 
  & $A₁$ and $A₂$ are disjoint if $A₁ ∩ A₂ = ∅$. \\
  Pairwise disjoint 
  & $A₁, A₂, …$ are pairwise disjoint if $A_i ∩ A_j = ∅$ for all $i$ and $j$ such that $i ≠ j$. \\
  Partition & If $A₁,A₂,…$ are pairwise disjoint and $⋃_{i=1}^∞ A_i = S$ then $\{A_i\}$ forms a partition of $S$. \\
  Power set & The power set of $S$, denoted $\mathcal{P}(S)$, is the set of all subsets of $S$.
  $\mathcal{P}(S) ≡ \{x : x ⊂ S\}$ \\
\bottomrule
\end{tabular}
  \caption{Collection of set operations; let $A₁$, $A₂$, $A₃$,... be subsets of another set $S$.}
  \label{tab:1}
\end{table*}

\item %
  \begin{defn} A collection $Ω$ of subsets of $S$ is a
    \emph{σ-algebra} if it satisfies the following
    \begin{enumerate}
    \item $S ∈ Ω$,
    \item $A^c ∈ Ω$ whenever $A ∈ Ω$, where $A^c = S ∖ A$,
    \item If $A₁$, $A₂$,… is a countable sequence with $A_i ∈ Ω$ for
      all $i$, then $⋃_{i=1}^∞ A_i ∈ Ω$ as well.
    \end{enumerate}
  \end{defn}

\item A pretty typical first example for σ-algebras involves coin
  flips.  But we're economists, so let's use a game.
  \begin{ex}[Matching pennies]
    For \emph{matching pennies}, there are two players (A and B) and
    each has a coin.  Each player chooses ``Heads'' or ``Tails''
    (secretly) and then they simultaneously show each other their
    coin.  If the coins match, player A wins and if they don't, player
    B wins.

    Now, let's model a single round of the game.  The sample space is
    the set $S = \{HH, HT, TH, TT\}$.\sidenote{Where, for example,
      \emph{HT} means that player A plays ``Heads'' and player B plays
      ``Tails''} There are, of course, several σ-algebras that can be
    constructed on this sample space.  For example, the σ-algebra that
    represents whether or not A plays ``Heads'' is
    \begin{equation*}
      \{∅, S, \{HH,HT\}, \{TH,TT\}\}
    \end{equation*}
    and the σ-algebra representing whether or not A wins is
    \begin{equation*}
      \{∅, S, \{HH,TT\}, \{TH,HT\}\}.
    \end{equation*}
    We can form the second σ-algebra by starting with the event ``A
    wins'' (i.e. the set $\{HH, TT\}$), and the sample space $S$, and
    then adding more sets as necessary so that the σ-algebra is closed
    under complements and countable unions.\sidenote{You should verify
      as an exercise that both of these sets are actually σ-algebras.}
  \end{ex}

\item This example gets at why we can view a σ-algebra as an
  \emph{information set}.  The σ-algebra, ``A plays Heads,'' contains
  all of the information we learn if we learn whether or not the event
  ``A plays Heads'' has happened.\sidenote{I.e., we learn whether or
    not A played Heads, and whether or not A played Tails.}  We might
  also view this as the information available to player A after
  choosing H or T, but before revealing his or her choice to B.

\item Now we can formally define a probability measure that obeys the
  same rules as before.
  \begin{defn} A function $\Pr$ is a \emph{probability measure} on a
    σ-algebra $Ω$ of subsets of $S$ if
    \begin{enumerate}
    \item $\Pr: Ω → [0,1]$
    \item if $A₁$, $A₂$,... are disjoint events in $Ω$ then
      $\Pr(⋃_{i=1}^∞ A_i) = ∑_{i=1}^∞ \Pr(A_i)$
    \item $\Pr(S) = 1$.
    \end{enumerate}
  \end{defn}
  
\item We refer to a sample space $S$, a σ-algebra $Ω$, and a
  probability measure $\Pr$ as a \emph{probability space}, $(S, Ω,
  \Pr)$.

\item Let's go back to the example,
  \begin{ex}[Matching pennies, continued]
    We can define strategies through the probability measure on a
    generating class, then use the properties over countable unions
    and intersections to extend it to the rest of the σ-algebra.

    We'll suppose that A plays a mixed strategy and chooses ``Heads''
    with probability 1/3 (and Tails with probability 2/3), and that B
    plays ``Heads'' with probability 4/5.  We'll also assume that
    neither player is cheating, so these choices are independent of
    each other.  This means that we have
    \begin{align*}
      \Pr \{HH\} &= (1/3) × (4/5) = 4/15 \\
      \Pr \{HT\} &= (1/3) × (1/5) = 1/15 \\
      \Pr \{TH\} &= (2/3) × (4/5) = 8/15 \\
      \Pr \{TT\} &= (2/3) × (1/5) = 2/15.
    \end{align*}
    We can write any other event as the union of these sets, so this
    lets us calculate the probability of any event in the game.  For
    example, the event, \emph{A wins} is the set $\{HH,TT\}$, and
    \begin{equation*}
      \Pr \{HH, TT\} = \Pr \{HH\} + \Pr \{TT\} = (4/15) + (2/15) = 6/15
    \end{equation*}
    (these strategies are obviously not a Nash equilibrium).
  \end{ex}
\end{itemize}

\section{Conditioning}

\begin{itemize}

\item Often, knowing that one event happens tells us something about
  how likely other events are.  In the Matching Pennies example we've
  used above, the probability that A wins is $6/15$.  If we know that
  A has played heads, we know that A wins if B plays heads too, which
  happens with probability $4/5$.

\item This was an example of conditioning on an event (e.g. the event
  that A plays heads).  The general formula for working out
  probabilities conditional on an event is as follows,

  \begin{defn}
    If $A$ and $B$ are events in some sample space $S$ and $\Pr[B] ≥
    0$, the \emph{conditional probability of $A$ given $B$} is written
    as $\Pr(A ∣ B)$ and defined to be
    \begin{equation*}
      \Pr(A ∣ B) ≡ \Pr(A ∩ B) / \Pr(B).
    \end{equation*}
    If $\Pr(B) = 0$ then we can define $\Pr(A ∣ B)$ arbitrarily to be
    zero.
  \end{defn}

  The equivalent formula
  \begin{equation*}
    \Pr(A ∩ B) = \Pr(A ∣ B) \Pr(B)
  \end{equation*}
  may make the interpretation easier: the probability that events $A$
  and $B$ happen is equal to the probability that $B$ happens times
  the probability that $A$ happened, knowing that $B$ already
  happened.\sidenote{Don't take the word ``already'' literally, since
    there is not time ordering implied by these formulas.}

\item Add diagram with conditional densities.

\item Observe that if $A$ and $B$ are mutually exclusive, then $\Pr(A
  ∩ B) = 0$, and so $\Pr(A ∣ B) = 0$.

\item We can use the definitions and the simple observation that
  \begin{equation*}
    \Pr(A ∣ B) \Pr(B) = \Pr(B ∣ A) \Pr(A)
  \end{equation*}
  to justify \emph{Bayes's Rule}:
  \begin{thm}[Bayes's Rule]
    If $A$ and $B$ are sets in $S$ that have positive probability, then
    \begin{equation*}
      \Pr(A ∣ B) = \Pr(B ∣ A) \Pr(A) / \Pr(B).
    \end{equation*}
  \end{thm}

\item We can generalize the idea of conditioning on a particular event
  to the idea of conditioning on an entire σ-field (information set).
  In the Matching Pennies example, we might want to know the
  probability of A winning given A's move.  This is now going to be a
  random variable: on the event ``A plays H'' the conditional
  probability takes on one value and on the event ``A plays T'' it
  takes on another value.

  The way to write this is $\Pr[A wins ∣ Ω]$ where $Ω$ is a σ-field.

\end{itemize}

\paragraph{independence}

      Two events are independent if knowing whether or not one
      happened does not help you know the probability of the second
\begin{description}
\item[Definition] events $A$ and $B$ are independent if \[P(A ∩
                      B) = P(A) P(B)\]
\item[implication] \[P(A ∣ B) = \frac{P(A ∩ B)}{P(B)} =
                       \frac{P(A) P(B)}{P(B)} = P(A)\]
\item[example] two coin flips
\begin{itemize}
\item A = ``first coin is heads'' = \{HT, HH\}
\item B = ``second coin is heads'' = \{TH, HH\}
\item under previous prob measure, A and B are independent: \[P(A
          ∩ B) = P(\{HH\}) = 1/4 \text{ and } P(A)P(B) = (1/2)² = 1/4\]
\end{itemize}
\end{description}

\subsection{random variables}

\begin{itemize}
\item we can map one event space (sigma-field) to another
\begin{itemize}
\item this lets us transfer the probability measure to another
        measurable space
\end{itemize}
\item most of the time, we map an abstract measureable space (ie hands
      of cards) to $\RR$
\begin{itemize}
\item imposes an ordering
\item imposes distance
\item lets us simplify things a lot more.
\end{itemize}
\item We're going to think about things like $P[X ∈ A]$ where $A
      \subset \RR$
\item The point of using random variables is to translate a very
      abstract ``experiment'' to concrete numbers.  In this situation,
      the sigma-field is giong to really let us think about the
      information conveyed by particular choices of rvs.
\item The ``borel sigma-field'', denoted $\mathcal B$, has the sample
      space $\RR$ and is the smallest sigma field containing the
      clo.sed intervals
\end{itemize}

\paragraph{definition of random variables}

\begin{itemize}
\item Let $\mathcal{F}$ be a sigma-field on a sample space $S$, and
        let $X$ be a function from $S$ to $\RR$.  $X$ is a random
        variable if it is ``measurable.''
\item $X$ is \underline{measurable} if $X^{-1}(B) ∈ \mathcal{F}$ for all $B
        ∈ \mathbb{B}$
\end{itemize}


\subsection{transformations}

\paragraph{introduction}

      Suppose we have a continuous random variable $X: S → \RR$.

\begin{itemize}
\item as we've discussed; this is just a way to define a new and more
        convenient probability space on the real line;
\item we know that $X$ has a distribution $F$ and a density $f$.
\item what happens if we look at $X²$ instead?
\begin{itemize}
\item it's an rv (don't worry about measurability
\item how are its distribution and density related to the distribution
          and density of the original random variable?
\end{itemize}
\end{itemize}

\paragraph{motivating example}

\begin{itemize}
\item Suppose $X$ has the mass function
\begin{itemize}
\item $P[X = 0] = 1/2$
\item $P[X = 1] = 1/4$
\item $P[X = 2] = 1/4$
\end{itemize}
(draw the distribution)
\item the mass for $X²$ is easy to guess:
  \[\Pr[X² = x] = \Pr[X = \sqrt{x}] =
  \begin{cases}
    1/2 & x = 0 \\
    1/4 & x = 1 \\
    1/4 & x = 4 \\
  \end{cases}
  \]
\end{itemize}

\paragraph{formula for density of a transformed rv}

\begin{itemize}
\item Available as Theorem B.5 in \citet{Gre12}.
\item Suppose that Y = g(X), where X is a random variable with density
        $f_X$ and g is a continuous, monotone function with continuously
        differentiable inverse.  The
        density of Y, $f_Y$, is given by the equation
        \[ f_Y(y) = f_X(g^{-1}(y)) | d/dy g^{-1}(y) | \]
        for y in the range of g and zero elsewhere
\item if g is not monotone, you need to split up the domain into parts
        over which g is monotone: see \citet{CB02} for details if
        you are interested.
\item do proof (comes from differentiating distribution function)
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../probability"
%%% End: 