% Copyright © 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Random variables, distributions, and densities}%
\addcontentsline{toc}{part}{Random variables, distributions, and densities}

\section{Random variables as we might wish to teach them to
  undergraduates.}

\begin{itemize}

\item We're trying to capture the idea of a ``hypothetical'' number
  that might take on many different values.  For example, if I were to
  go to Las Vegas next weekend, I might win \$10 while I'm there; I
  might win \$1,000; I might ``win'' --\$5,000; etc.  If we're going
  to talk meaningfully about what might happen if I go to Las Vegas,
  we're going to need a way to match each outcome (here how much money
  I win or lose) with the relative frequency of that outcome.

  The simplest\sidenote{``Simplest'' from a conceptual/intuitive
    standpoint; we'll see that this is far from the simplest way from
    a rigorous mathematical standpoint.}  way to do this is through a
  probability density function and, as in most of probability, the
  easiest way to start is to work with discrete events (in which case
  the ``density'' function us usually called a ``probability mass
  function'').  Suppose that we're interested in a countable number of
  possible outcomes on the real line; think of handful of dice and
  adding up all of the numbers, so the possible values that the sum
  can take on are in some set $S = \{x_i ∣ i ∈ \ZZ\}$, where \ZZ\ is
  the set of integers.  Then we can define a probability density
  function $f: \RR → \RR$ as the function such that
  \begin{enumerate}
  \item $f(x) ≥ 0$ for all $x ∈ \RR$,
  \item $f(x) = 0$ for all $x ∉ S$, and
  \item $∑_{x ∈ S} f(x_i) = 1$.
  \end{enumerate}

  So now we can think of a random variable $X$ that takes on values in
  the set $\mathcal{X}$ with probabilities given by $f$.  And we can
  build a probability function from a density $f$ for the random
  variable $X$ by asserting that, for any $A ⊂ S$,
  \begin{equation*}
    \Pr[ X ∈ A ] = ∑_{s ∈ A} f(s)
  \end{equation*}

\item If we want to let $X$ take on the entire range of values in \RR\
  we can proceed the same way.  Again define the density function $f:
  \RR → \RR$ such that
  \begin{enumerate}
  \item $f(x) ≥ 0$ for all $x ∈ \RR$ and
  \item $∫_{-∞}^∞ f(x) dx = 1$.
  \end{enumerate}
  We can again build a probability function from the density function.
  For any closed interval $[a, b]$, we can define
  \begin{equation*}
    \Pr[ X ∈ [a,b] ] = ∫_a^b f(x) dx,
  \end{equation*}
  and for any set $A$ that can be written as the union of a countable
  number of disjoint intervals, $A = ⋃_i [a_i, b_i]$, we can define
  \begin{equation*}
    \Pr[ X ∈ A ] = \sum_i ∫_{a_i}^{b_i} f(x) dx.
  \end{equation*}

\item It's natural to want to go even further, and define for any set
  $A ⊂ \RR$
  \begin{equation*}
    \Pr[ X ∈ A ] = ∫_A f(x) dx ≡ ∫_{-∞}^∞ 1\{x ∈ A\} f(x) dx,
  \end{equation*}
  but it turns out that this integral is not well-defined for every $A
  ⊂ \RR$ (and, consequently, it's possible to construct functions $f$
  that can't be used as densities, a fact that we glossed over
  earlier).  However, it should be obvious that we can construct a
  self-contained set of subsets of \RR, call it \BB, so that we can
  define $\Pr[X ∈ B] = ∫_B f(x) dx$ for all $B ∈ \BB$.

  We can motivate some of properties that \BB\ needs from properties
  that seem necessary for the probability function $\Pr$.

  \begin{enumerate}
  \item We need $\Pr[X ∈ \RR] = ∫_{-∞}^∞ f(x) dx = 1$, so \RR\ must be
    in \BB.
  \item If $\Pr[X ∈ B]$ is well defined then $\Pr[X ∉ B]$ should be as
    well, and we should have $\Pr[X ∉ B] = 1 - \Pr[X ∈ B]$.  Since $X
    ∉ B$ is equivalent to $X ∈ B^c$, $B^c$ must be in \BB\ whenever
    $B$ is.
  \item If $B₁$, $B₂$, $B₃$,… make up a countable sequence of sets and
    we can define $\Pr[X ∈ B_i]$ for each of them, we should be able
    to define $\Pr[X ∈ ⋃_i B_i]$ and $\Pr[X ∈ ⋂_i B_i]$.  So \BB\ must
    be closed under countable unions and intersections.
  \end{enumerate}

  Any set of sets \BB\ that satisfies those three properties is called
  a \emph{sigma-algebra} (or \emph{σ-algebra}).  For subsets of the
  real line, there's an especially useful and common σ-algebra, the
  \emph{Borel σ-algebra},which is defined as the smallest σ-algebra
  that has all of the intervals as elements.

\item The integral we're interested is a little different than the
  usual Riemann integral that you've seen in introductory calculus
  classes, but not in any way that's going to matter in practice.  The
  key difference is that it works by taking different points in the
  function's height and mapping them back to Borel sets in the
  function's domain, while the Riemann integral works by taking
  different points in the function's domain and mapping them to the
  height.\sidenote{Remember, to get the Riemann integral of a function
    $g: \RR → \RR$ over $[a,b]$, first define an increasingly fine
    partition of $[a,b]$, $\{x_{i,n}, i = 1,…n, n = 1,2,…\}$ such that
    $a = x_{1,n}$, $b = x_{n,n}$, $x_{i,n} < x_{i+1,n}$ for all $i$
    and $\max_{i=1,…,n-1} |x_{i+1,n} - x_{i,n}| → 0$ as $n → ∞$.  If
    we let $M_i = \max_{x ∈ [x_{i,n}, x_{i+1,n}]} g(x)$ and $m_i =
    \min_{x ∈ [x_{i,n}, x_{i+1,n}]} g(x)$, then the Riemann integral
    exists if
    \begin{multline*}
      \lim_{n → ∞} ∑_{i=1}^{n-1} M_i (x_{i+1,n} - x_{i,n}) \\
      = \lim_{n → ∞} ∑_{i=1}^{n-1} m_i (x_{i+1,n} - x_{i,n})
    \end{multline*}
    for any partition $\{x_{n,i}\}$.} 
  So, if $g$ is any step function that can be written as a step
  function of Borel sets,
  \begin{equation*}
    g(x) = ∑_{i=1}^∞ c_i 1\{x ∈ B_i\}
  \end{equation*}
  where $B_i ∈ \BB$, we can define the Lebesgue integral as
  \begin{equation*}
    ∫ g dμ = ∑_{i=1}^∞ c_i μ(B_i),
  \end{equation*}
  where $μ(B_i)$ is the length of the set $B_i$.\sidenote{I should
    maybe add a definition or an Appendix on Lebesgue measure, but
    that will probably happen later.}  The integrals of functions that
  are not step functions can be evaluated as the limit of the integral
  of step functions.  

  For all of this to work, we need to be able to find a Borel set in
  the domain of the function for any set of points in the range;
  i.e. for the step function above, we have, for any point $x$,
  \begin{equation*}
    g^{-1}(\{x\}) =
    \begin{cases}
      B_i & x = c_i \\
      ∅ & x ∉ \{c₁, c₂,…\}
    \end{cases}
  \end{equation*}
  and, for any $B ∈ \BB$, $g^{-1}(B) = ⋃_{i ∈ I} B_i$ where $I = \{i ∣
  c_i ∈ B\}$.\sidenote{You should prove on your own that this means
    that $\{g^{-1}(B) ∣ B ∈ \BB\}$ is a σ-algebra and is a subset of
    \BB.}

\item The key proprerty, then, for this integral to work is that
  $g^{-1}(\BB)$ itself be a σ-algebra that is contained in \BB.  Such
  a function is called \emph{Borel-measurable}.  We're going to
  restrict our focus to densities $f$ that are Lebesgue measurable,
  which are Lebesgue-measurable, so we can always write probabilities
  as
  \begin{equation*}
    \Pr[X ∈ B] = ∫_B f(x) dx
  \end{equation*}
  for Borel-sets $B$.  We won't be able to define these probabilities
  for non-Borel sets, but that's fine; in this case, every function
  that we'd want to work with is Lebesgue-measurable and every set
  that we'd want to work with is a Borel set.\sidenote{Add example of
    unmeasurable set here....}

  If we're clever, we can define probabilities for discrete random
  variables the same way.  Define the function $δ$, known as Dirac's
  δ-function, as $δ = \lim_{n → ∞} δ_n$ where
  \begin{equation*}
    δ_n(x) =
    \begin{cases}
      n + n² x & - \tfrac{1}{n} ≤ x ≤ 0 \\
      n - n² x & 0 < x ≤ \tfrac{1}{n} \\
      0        & \text{otherwise},
    \end{cases}
  \end{equation*}
  so each $δ_n$ is a very narrow, very tall spike at 0 with total area
  1, and as $n$ grows the spike gets narrower and higher.  The limit
  $δ$ is an infinitely tall, infinitely narrow spike at 0 with total
  area 1.

  Under Lebesgue-measure, we can now define the density of a
  Bernoulli(1/2) random variable $b$ as
  \begin{equation*}
    f_b(x) = \tfrac{1}{2} δ(x) + \tfrac{1}{2} δ(x - 1).
  \end{equation*}
  This lets us write $\Pr[b ∈ B] = ∫_B f_b(x) dx$ for any Borel-set
  $B$, which is what we want.\sidenote{You should work through all of
    the steps necessary to prove this to yourself.}
\end{itemize}

\section{Sigma-algebras as information sets}

\begin{itemize}

\item In the previous section, we motivated the Borel σ-algebra as a
  collection of sets that it makes sense to assign length to, and that
  it makes sense to talk about the ``Probability'' of a random
  variable landing in.  As you've probably seen elsewhere, we should
  think of a random variable is a way of numerically summarizing a
  random outcome.

\item Sometimes it doesn't make sense to assign numeric values right
  away, though.  If we want to think about modeling card games, the
  events that we might be concerned with are different hands that we
  might be dealt.  But it might not make sense to summarize that
  information numerically unless we have already set a particular
  game.  Fortunately, the key properties that we were discussing
  beforehand don't need to be specific to numbers.

  In general, we can call the set of all possible outcomes of a
  (possibly hypothetical) experiment the \emph{sample space} of the
  experiment, and let $Ω$ be the \emph{σ-algebra} of the experiment if
  it satisfies the rules we discussed above.  The elements of $Ω$ are
  usually refered to as \emph{events}.

\item %
  \begin{defn} A collection $Ω$ of subsets of $S$ is a
    \emph{σ-algebra} if it satisfies the following
    \begin{enumerate}
    \item $S ∈ Ω$,
    \item $A^c ∈ Ω$ whenever $A ∈ Ω$, where $A^c = S ∖ A$,
    \item If $A₁$, $A₂$,… is a countable sequence with $A_i ∈ Ω$ for
      all $i$, then $⋃_{i=1}^∞ A_i ∈ Ω$ as well.
    \end{enumerate}
  \end{defn}

\item Motivate general probability measures now!

\item %
  \begin{defn} A function $\Pr$ is a \emph{probability measure} on a
    σ-algebra $Ω$ of subsets of $S$ if
    \begin{enumerate}
    \item $\Pr: Ω ↦ [0,1]$
    \item if $A₁$, $A₂$,… are disjoint events in $Ω$ then
      $\Pr(⋃_{i=1}^∞ A_i) = ∑_{i=1}^∞ \Pr(A_i)$
    \item $\Pr(S) = 1$.
    \end{enumerate}
  \end{defn}
  
\item We refer to a sample space $S$, a σ-algebra $Ω$, and a
  probability measure $\Pr$ as a \emph{probability space}, $(S, Ω,
  \Pr)$.

\end{itemize}

\paragraph{Matching pennies example:}

\begin{itemize}
\item Use ``matching pennies'' as an example
\begin{itemize}
\item outcomes: HH, HT, TH, TT
\item sample space is \{HH, HT, TH, TT\}
\end{itemize}
\item Define strategies here too:
\begin{itemize}
\item Prob A plays H is 1/3
\item Prob B plays H is 4/5
\end{itemize}
\item events: subsets of \{HH, HT, TH, TT\}
\begin{itemize}
\item Ie, the event that player B wins is \{HT, TH\}
\end{itemize}
\item Want to assign probabilities to events using the strategy above
\begin{itemize}
\item Assign to a smaller set of manageable events (generating
          class) and then use rules to extend to other events.
\begin{itemize}
\item Generating class: \{{HH\}, \{HT\}, \{TH\}, \{TT\}}
\begin{description}
\item[.] Note this \textbf{isn't} a sigma field
\end{description}
\end{itemize}
\item Just going by what we wrote earlier:
\begin{description}
\item[.] P(A plays heads) = 1/3 = P(\{HH, HT\}) = P(\{HH\}) + P(\{HT\})
\item[.] P(A plays tails) = 2/3 = P(\{TH, TT\}) = P(\{TH\}) + P(\{TT\})
\item[.] P(B plays heads) = 4/5 = P(\{HH, TH\}) = P(\{HH\}) + P(\{TH\})
\item[.] P(B plays tails) = 1/5 = P(\{HT, TT\}) = P(\{HT\}) + P(\{TT\})
\end{description}
\item Four unknowns, four equations; solve to get probabilities:
\begin{itemize}
\item P(\{HH\}) = 4/15
\item P(\{HT\}) = 1/15
\item P(\{TH\}) = 8/15
\item P(\{TT\}) = 2/15
\end{itemize}
\end{itemize}
\item Sigma fields:
\begin{itemize}
\item Player A's info set: \{S, $∅$, \{HH, HT\}, \{TH, TT\}\}
\item Player B's info set: \{S, $∅$, \{HH, TH\}, \{HT, TT\}\}
\item Sigma field denoting whether or not A wins: \{S, $∅$, \{HH,
  TT\}, \{HT, TH\}\}
\item Power set is a sigma field too
\end{itemize}
\end{itemize}

\section{Set Theory and Probability Spaces}

\subsection{Key concepts}

\begin{itemize}
\item Probability space, a mathematical model for a statistical experiment
\item Random variable, a map that assigns numbers to outcomes in the
       statisical experiment
\end{itemize}

\subsection{Table of set theory results}

This stuff is kind of important for working with probability spaces,
but I don't enjoy lecturing on it.  Here you go!  Learn!

Let $A₁$, $A₂$, $A₃$,… be subsets of another set $S$

\begin{fullwidth}
\begin{tabular}{lp{4in}}
  \toprule
  \multicolumn{2}{c}{Finite Set Operations} \\
  \midrule
  Union        & $A₁ ∪ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ or } x∈ A₂\}$ \\
  Intersection & $A₁ ∩ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ and } x ∈ A₂\}$ \\
  Subset       & $A₁ ⊂ A₂$ if $A₁ ∩ A₂ = A₁$ \\
  Equality     & $A₁ = A₂$ if $A₁ ⊂ A₂$ and $A₂ ⊂ A₁$ \\
  Complement   & $A₁^c ≡ \{x ∈ S : x ∉ A₁\}$ \\
  Difference   & $A₁ ∖ A₂ ≡ \{x ∈ S : x ∈ A₁ \text{ and } x ∉ A₂\}$ \\
  Symmetric difference & $A₁ ▵ A₂ ≡ (A₁ ∖ A₂) ∪ (A₂ ∖ A₁)$ \\
  \midrule
  \multicolumn{2}{c}{Infinite Set Operations (can be defined for uncountable index sets as well)} \\
  \midrule
  Union        & $⋃_{k=1}^∞ A_k ≡ \{x ∈ S : x ∈ A_k$ for at least one $k ∈ 1,2,…\}$ \\
  Intersection & $⋂_{k=1}^∞ A_k ≡ \{x ∈ S : x ∈ A_k$ for all $k ∈ 1,2,…\}$ \\
  Infimum      & $\inf_{k ≥ n} A_k ≡ ⋂_{k=n}∞ A_k$ \\
  Supremum     & $\sup_{k ≥ n} A_k ≡ ⋃_{k=n}^∞ A_k$ \\
  lim inf      & $\liminf_{n → ∞} A_n ≡ ⋃_{n=1}^∞ ⋂_{k=n}^∞ A_k$ \\
  lim sup      & $\limsup_{n → ∞} A_n ≡ ⋂_{n=1}^∞ ⋃_{k=n}^∞ A_k$ \\
  \midrule
  \multicolumn{2}{c}{Other definitions} \\
  \midrule
  limit 
  & Suppose that $A, A₁, A₂, …$ is a sequence of subsets of $S$ and that $\limsup_{n → ∞} A_n = \liminf_{n → ∞} A_n = A$.
  Then $A$ is the limit of $\{A_n\}$. \\
  Disjoint 
  & $A₁$ and $A₂$ are disjoint if $A₁ ∩ A₂ = ∅$. \\
  Pairwise disjoint 
  & $A₁, A₂, …$ are pairwise disjoint if $A_i ∩ A_j = ∅$ for all $i$ and $j$ such that $i ≠ j$. \\
  Partition & If $A₁,A₂,…$ are pairwise disjoint and $⋃_{i=1}^∞ A_i = S$ then $\{A_i\}$ forms a partition of $S$. \\
  Power set & The power set of $S$, denoted $\mathcal{P}(S)$, is the set of all subsets of $S$.
  $\mathcal{P}(S) ≡ \{x : x ⊂ S\}$ \\
\bottomrule
\end{tabular}
\end{fullwidth}

\paragraph{conditioning on an event}

\begin{itemize}
\item Often, knowing that one event happens tells us something about
        how likely other events are
\begin{itemize}
\item Say we know A plays heads; what's the prob. that A wins?
\item In this example, it's obviously the probability that B plays
          heads (4/5), but we can get a formula as well
\end{itemize}
\item Definition \citep[Definition 1.3.2]{CB02}: if \emph{A} and
  \emph{B} are events in \emph{S}, and $P(B) > 0$, then ``the
  conditional probability of A given B'', written as $P(A ∣ B)$, is
        \[P(A ∣ B) = \frac{P(A ∩ B)}{P(B)}\]
\begin{itemize}
\item note: $A$ and $B$ are mutually exclusive means $P(A ∩
          B) = 0$, and we have $P(A ∣ B) = 0$ as well.
\item obviously, $P(B ∣ B) = 1$
\item verify that it's a probability measure.
\end{itemize}
\item Bayes's Rule \citep[Theorem 1.3.5, which is more complicated]{CB02}:
        Let $A$ and $B$ be any sets in $S$ with positive probability.
        Then \[P(A ∣ B) = P(B ∣ A) P(A) / P(B)\]
\item Continue Example from earlier:
        \[P(A wins | A plays heads) = P({HH, TT} | {HH, HT}) =
        \frac{P(\{HH, TT\} ∩ \{HH, HT\})}{P(\{HH, HT\})} =
        \frac{4/15}{1/3} = 4/5\]
\end{itemize}

\paragraph{independence}

      Two events are independent if knowing whether or not one
      happened does not help you know the probability of the second
\begin{description}
\item[Definition] events $A$ and $B$ are independent if \[P(A ∩
                      B) = P(A) P(B)\]
\item[implication] \[P(A ∣ B) = \frac{P(A ∩ B)}{P(B)} =
                       \frac{P(A) P(B)}{P(B)} = P(A)\]
\item[example] two coin flips
\begin{itemize}
\item A = ``first coin is heads'' = \{HT, HH\}
\item B = ``second coin is heads'' = \{TH, HH\}
\item under previous prob measure, A and B are independent: \[P(A
          ∩ B) = P(\{HH\}) = 1/4 \text{ and } P(A)P(B) = (1/2)² = 1/4\]
\end{itemize}
\end{description}

\subsection{random variables}

\begin{itemize}
\item we can map one event space (sigma-field) to another
\begin{itemize}
\item this lets us transfer the probability measure to another
        measurable space
\end{itemize}
\item most of the time, we map an abstract measureable space (ie hands
      of cards) to $\RR$
\begin{itemize}
\item imposes an ordering
\item imposes distance
\item lets us simplify things a lot more.
\end{itemize}
\item We're going to think about things like $P[X ∈ A]$ where $A
      \subset \RR$
\item The point of using random variables is to translate a very
      abstract ``experiment'' to concrete numbers.  In this situation,
      the sigma-field is giong to really let us think about the
      information conveyed by particular choices of rvs.
\item The ``borel sigma-field'', denoted $\mathcal B$, has the sample
      space $\RR$ and is the smallest sigma field containing the
      clo.sed intervals
\end{itemize}

\paragraph{definition of random variables}

\begin{itemize}
\item Let $\mathcal{F}$ be a sigma-field on a sample space $S$, and
        let $X$ be a function from $S$ to $\RR$.  $X$ is a random
        variable if it is ``measurable.''
\item $X$ is \underline{measurable} if $X^{-1}(B) ∈ \mathcal{F}$ for all $B
        ∈ \mathbb{B}$
\end{itemize}

\section{Distribution functions}

\subsection{definition}

     The cumulative distribution function of a random variable $X$,
     denoted $F_X$, is defined by $F_X(x) = P[X ≤ x]$ for all x.

\subsection{properties}

     The distribution function of a random variable always exists and
     satisfies
\begin{enumerate}
\item $\lim_{x → -∞} F_X(x) = 0$
\item $\lim_{x → ∞} F_X(x) = 1$
\item $F_X$ is non-decreasing in $x$.
\item $F_X$ is right-continuous.  For every number $x₀$, $\lim_{x
        \downarrow x₀} F(x) = F(x₀)$
\end{enumerate}

\subsection{additional definitions}

     A random variable is \emph{discrete} if its cdf is a step function and
     is \emph{continuous} if its cdf is continuous.  (our previous example is
     neither discrete nor continuous)

\subsection{basic property}

\begin{itemize}
\item $\Pr[X ∈ (a, b]] = F_X(b) - F_X(a)$
\end{itemize}

\section{Densities}

\subsection{motivation}

     The cdf is awkward to work with directly.  Often we really want to
     know something like the probability that a random variable $X$
     equals a specific value.

\subsection{discrete rv}

     For discrete rv, talking about the probability that the rv takes a
     specific value is meaningful.

\paragraph{definition of probability mass function}

\begin{itemize}
\item Definition: the probability mass function of a discrete rv
        $X$, denoted $f_X(x)$, is defined as $P(X = x)$ for all $x$.
\item I'm going to call these ``densities'' from now on; you should know
        this terminology for the future, though.
\end{itemize}

\paragraph{relationship between pmf and distribution}

      The mass function and the distribution function are related by:
      \[F_X(x) = ∑_{y ≤ x} f_X(y)\]

\subsection{continuous random variables.}

\begin{itemize}
\item The probability that a continuous r.v. takes a specific value
       is zero:
\begin{itemize}
\item suppose $\Pr[X = x] > \ep$ for ever $x ∈ [0,1]$.
\item Then
  \[\Pr[X=x₁ ∪ X = x₂ ∪ ⋯ ∪ X = x_n] = ∑_{i=1}^n \Pr[X = x_i] = n \ep\]
  for distinct $x₁,...,x_n$
\item if $\ep > 0$ then $\Pr[X = x₁ ∪ ... ∪ X = x_n] > 1$ for all
  $n > 1/\ep$, which is a contradiction
\end{itemize}
\item The relationship between the distribution function and the mass
  function should remind you of \[ F_X(x) = ∫_{ -∞}^{x} f_X(y) dy.\]
\item We're going to take this relationship as our starting point for
       the continuous random variables
\end{itemize}

\paragraph{definition}

      The probability density function (pdf) of a continuous random
      variable $X$ with distribution $F_X(·)$ is the function $f_X$
      that satisfies \[ F_X(x) = ∫_{-∞}^{x} f_X(y) dy\]

\paragraph{notes}

\begin{itemize}
\item if $F$ is differentiable, we can get $f$ by differentiation.
\item continuous random variables take on any particular value
        with probability zero
\item if you're comfortable using Dirac's delta function, this second
        definition encompasses both the continuous and discrete case
        (which is why I'll call both cases `pdfs').
\item The \underline{support} of a random variable is the set of points where
        its density is positve: $\{x ∈ \RR ∣ f_X(x) > 0\}$
\end{itemize}

\subsection{properties of densities}

\begin{itemize}
\item $f_X(x) ≥ 0$ for all $x$
\item for discrete rv: $∑_x f_X(x) = 1$
\item for continuous rv: $∫_{-∞}^{∞} f_X(y) dy = 1$
\end{itemize}

\subsection{transformations}

\paragraph{introduction}

      Suppose we have a continuous random variable $X: S → \RR$.

\begin{itemize}
\item as we've discussed; this is just a way to define a new and more
        convenient probability space on the real line;
\item we know that $X$ has a distribution $F$ and a density $f$.
\item what happens if we look at $X²$ instead?
\begin{itemize}
\item it's an rv (don't worry about measurability
\item how are its distribution and density related to the distribution
          and density of the original random variable?
\end{itemize}
\end{itemize}

\paragraph{motivating example}

\begin{itemize}
\item Suppose $X$ has the mass function
\begin{itemize}
\item $P[X = 0] = 1/2$
\item $P[X = 1] = 1/4$
\item $P[X = 2] = 1/4$
\end{itemize}
(draw the distribution)
\item the mass for $X²$ is easy to guess:
  \[\Pr[X² = x] = \Pr[X = \sqrt{x}] =
  \begin{cases}
    1/2 & x = 0 \\
    1/4 & x = 1 \\
    1/4 & x = 4 \\
  \end{cases}
  \]
\end{itemize}

\paragraph{formula for density of a transformed rv}

\begin{itemize}
\item Available as Theorem B.5 in \citet{Gre12}.
\item Suppose that Y = g(X), where X is a random variable with density
        $f_X$ and g is a continuous, monotone function with continuously
        differentiable inverse.  The
        density of Y, $f_Y$, is given by the equation
        \[ f_Y(y) = f_X(g^{-1}(y)) | d/dy g^{-1}(y) | \]
        for y in the range of g and zero elsewhere
\item if g is not monotone, you need to split up the domain into parts
        over which g is monotone: see \citet{CB02} for details if
        you are interested.
\item do proof (comes from differentiating distribution function)
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../probability"
%%% End: 