% Copyright Â© 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Overview of point estimation}%
\addcontentsline{toc}{part}{Overview of point estimation}

\begin{itemize}

\item We're not learning probability for its own sake; we actually
  want to talk about statistical estimators and the probability tools
  that we've learned are going to help.

\item we want to think about datasets as a particular instance of an
  unobserved random process.  Most datasets have the form (and I'll do
  a macro dataset)
  \begin{description}
  \item[time period] \ldots{},2009:01, 2009:02, 2009:3,\ldots{}
  \item[unemployment] \ldots{},7.6, 8.1, 8.5,\ldots{}
  \item[CPI] 212.174, 213.007, 212.714,\ldots{}
  \end{description}
  we can think of this as a sequence of 2-vectors
  \begin{itemize}
  \item t will be the index (if we have data starting in 1970, t would
    be 1 in Jan of 1970, 2 in Feb of 1970),\ldots{},468 in 2009:01, 469
    in 2009:02, etc.
  \item $x_t$ will be the \emph{observed values} of unemployment and cpi in
    month t
    \begin{itemize}
    \item $x_{468} = (7.6, 212.174)$
    \item $x_{469} = (8.1, 213.007)$
    \item etc.
    \end{itemize}
  \end{itemize}

  So, this is the data -- $x_1,\dots,x_T$.

\item The Working assumptions are
  \begin{itemize}
  \item data were generated by some sort of hypothetical experiment (DGP).
  \item we want to use the data to estimate features of the DGP
  \end{itemize}

  DGP might be $X_t \sim N(\mu, \sigma^2)$; the $x_t$ are realizations
  of $X_t$ and we want to estimate $\mu$ and $\sigma^2$,

\item or $\Delta p_t = g(\Delta p_{t-1}, \Delta p_{t-2}, \dots; u_{t-1}, u_{t-2}, \dots) + \varepsilon_t$;

  \begin{itemize}
  \item $\varepsilon_t$ is independent of $\Delta p_{t-1}, \Delta p_{t-2}, \dots$ and $u_{t-1}, u_{t-2}, dots$
  \item $g$ is smooth
  \item want to estimate $\frac{\partial}{\partial u_{t-1}} g$
  \end{itemize}

\item The DGP we write down doesn't need to be true, but some
  statistics will be more sensitive than others to how ``true'' the
  model is.

\end{itemize}

\section{Definition of estimators}
Let $x_1,\dots,x_n$ be a dataset.  A function of that dataset,
$T(x_1,\dots,x_n)$ is called a \emph{statistic} or \emph{estimator}.

\begin{itemize}
\item examples:
\begin{itemize}
\item $T(x_1,\dots,x_n) = 1/2$
\item $T(x_1,\dots,x_n) = n^{-1} \sum_{i=1}^n x_i$
\item histogram
\end{itemize}
\item Can't depend on the true DGP
\begin{itemize}
\item $T(x_1,\dots,x_n) = E X_1$ is not an estimator
\end{itemize}
\item so a statistic just takes the numbers you see, and summarizes
      them.  Anything that does that is called a statistic.
\begin{itemize}
\item even if the ``summary'' is stupid.  for example, if you
        ``summarize'' the numbers with 0, it is a statistic (as far as the
        theory is concerned).
\item The ``summary'' can also be random.  We won't get into that too
        much this class.
\end{itemize}
\item So, there are lots of things that are bad or uninformative that
      we're going to treat as statistics/estimators.
\begin{itemize}
\item But that's okay, because we haven't developed any way to say
        that an estimator is ``bad'' or ``good'' yet.
\item until we do, we can't say that summarizing a dataset with the
        mean of each of its variables is ``good'' and summarizing the
        dataset with the number 0 is ``bad''.
\item moreover, letting ``bad'' things count as estimators helps us
        define what ``good'' means.
\end{itemize}
\item we are talking about the \textbf{function}, not the value it takes on.
\begin{itemize}
\item estimators are random variables
\item the realization is an \emph{estimate}.
\end{itemize}
\end{itemize}

\section{Method of Moments}

\begin{itemize}
\item Suppose we have $X_1,\dots,X_n \sim f(x; \theta)$
\begin{itemize}
\item $f$ is known
\item $\theta$ is an unknown $p$-vector that we want to estimate
\end{itemize}
\item estimator is based on a simple idea:
\begin{itemize}
\item if we want to estimate an expectation, use a sample average
\item $P[X_i \leq c]$ for known $c$
\begin{itemize}
\item $=E 1\{X_i \leq x\}$
\item estimate with $n^{-1} \sum_{i=1}^n 1\{X_i \leq c\}$
\end{itemize}
\item Estimate $\E X_i$ with $n^{-1} \sum_{i=1}^n X_i$
\item etc
\end{itemize}
\item in general, relate $\theta$ to the population moments:
\begin{itemize}
\item if $\theta$ has $p$ elements, we calculate the first $p$ moments
        of $X_i$
\begin{itemize}
\item $\mu_1 = g_1(\theta)$
\item $\mu_2 = g_2(\theta)$
\item dot dot dot
\item $\mu_p = g_p(\theta)$
\end{itemize}
\end{itemize}
\item calculate the sample moments:
\begin{itemize}
\item $\hat \mu_1 = n^{-1}\sum_{i=1}^n X_i$
\item $\hat \mu_2 = n^{-1}\sum_{i=1}^n X_i^2$
\item dot dot dot
\item $\hat \mu_p = n^{-1}\sum_{i=1}^n X_i^p$
\end{itemize}
\item estimate $\theta$ by setting the equations equal:
\begin{itemize}
\item $g_1(\hat\theta) = \hat\mu_1 = n^{-1}\sum_{i=1} X_i$
\item dots
\item $g_p(\hat\theta) = \hat\mu_p = n^{-1}\sum_{i=1} X_i^p$
\item then $\hat\theta = g^{-1}(n^{-1}\sum_{i=1}^n
        X_i,\dots,n^{-1}\sum X_i^p)$
\begin{itemize}
\item obviously, $g$ needs to be invertible for this to work.
\end{itemize}
\end{itemize}
\item Sometimes $\hat\theta$ is easy to write out analytically as a
      function of the sample averages
\begin{itemize}
\item when it's not, you can find $\hat \theta$ numerically.
\end{itemize}
\item if each sample moment is close to the population moment and
      $g^{-1}$ is continuous, then $\hat\theta$ should be close to $\theta$.
\end{itemize}

\section{Examples}

\begin{itemize}
\item normal$(\mu,\sigma^2)$
\begin{itemize}
\item first moment of a normal random variable is $E X_i = \mu$
\item second moment is $E X_i^2 = \sigma^2 + \mu^2$
\item method of moments estimator is
\begin{itemize}
\item $\hat \mu = n^{-1} \sum_i X_i$
\item $\hat \sigma^2 = n^{-1} \sum_i X_i^2 - (n^{-1}\sum_i X_i)^2
           = n^{-1} \sum_i(X_i - \bar X)^2$
\item which is not the usual estimator, but is close.
\end{itemize}
\end{itemize}
\item uniform(a,b)
\begin{itemize}
\item Let's say that $X_1,\dots,X_n$ are iid uniform$(a,b)$, and we want
         to calculate the method of moments estimator for $a$ and $b$.
\begin{itemize}
\item density of $X_i$ is $1/(b-a)$ in $[a,b]$, zero otherwise.
\end{itemize}
\item Calculate the first two moments:
\begin{itemize}
\item $E X_i = \int_a^b x /(b-a) dx = \frac{b+a}{2}$
\item $E X_i^2 = \int_a^b x^2 /(b-a) dx = \frac{b^3 - a^3}{3(b - a)} = \frac{b + ab + a^2}{3}$
\end{itemize}
\item Gives the estimators:
\begin{itemize}
\item $\hat b+\hat a = 2 n^{-1} \sum_i X_i$
\item ${\hat b^3-\hat a^3 \over (\hat b- \hat a)} = 3 n^{-1} \sum_i X_i^2$
\item solve for $\hat b$ and $\hat a$, gives
\begin{itemize}
\item $\hat b = \bar X + s \sqrt{3}$
\item $\hat a = \bar X - s \sqrt{3}$
\item $s = \sqrt{n^{-1} \sum_i (X_i - \bar X)^2}$
\end{itemize}
\end{itemize}
\end{itemize}
\item linear regression
\begin{itemize}
\item setup
\begin{itemize}
\item \$(Y$_i$, X$_i$) $\sim$ i.i.d.\$
\item $X_i \sim f$ (unspecified)
\item $Y_i \mid X_i \sim N(\beta_0 + \beta_1 X_i, \sigma^2)$
\item want to estimate $\beta_0$ and $\beta_1$
\item draw scatterplot (this is like estimating the slope and intercept)
\item We'll often see this as $Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$
\begin{itemize}
\item $\varepsilon_i \mid X_i \sim N(0, \sigma^2)$
\item i.e. define $\varepsilon_i = Y_i - \beta_0 - \beta_1 X_i$
\end{itemize}
\end{itemize}
\item MoM estimator
\begin{itemize}
\item we know $E \binom{Y_i}{X_i Y_i} = \begin{pmatrix} \beta_0 + \beta_1 E X_i \\ \beta_0 E X_i + \beta_1 E X_i^2 \end{pmatrix}$
\begin{itemize}
\item $= \begin{pmatrix} 1 & E X_i \\ E X_i & E X_i^2 \end{pmatrix} \begin{pmatrix}\beta_0 \\ \beta_1\end{pmatrix}$
\end{itemize}
\item Assuming invertibility, $\begin{pmatrix}\beta_0\\\beta_1\end{pmatrix} = \begin{pmatrix}1&EX_i\\EX_i&EX_i^2\end{pmatrix}^{-1} \begin{pmatrix}EY_i\\EX_iY_i\end{pmatrix}$
\item This makes our estimator, $\begin{pmatrix}\hat\beta_0\\\hat\beta_1\end{pmatrix}=\begin{pmatrix}1&\sum_i x_i/n\\\sum_i x_i/n&\sum_ix_i^2/n\end{pmatrix}^{-1}\begin{pmatrix}\sum_iy_i/n\\\sum_ix_iy_i/n\end{pmatrix}$
\begin{itemize}
\item $=\begin{pmatrix}1&\sum_i x_i\\\sum_i x_i&\sum_ix_i^2\end{pmatrix}^{-1}\begin{pmatrix}\sum_iy_i\\\sum_ix_iy_i\end{pmatrix}$
\item (write in matrix notation and explain)
\end{itemize}
\end{itemize}
\end{itemize}
\end{itemize}

\section{Discussion}

\begin{itemize}
\item advantages
\begin{itemize}
\item it gets you an estimator
\item easy to derive asymptotic properties of the estimator (it's a
         function of averages, which usually obey CLTs and LLNs).
\end{itemize}
\item disadvantages
\begin{itemize}
\item can be very inefficient
\item for it to be useful, requires that the moments tell you a lot
         about the distribution (for the uniform, they don't
         necessarily -- we're trying to estimate the endpoints, but our
         estimator is to look for the center and double it.)
\begin{itemize}
\item a big problem with our estimates here, is we might have \$X\$s
           in our data that are outside the interval $[a,b]$
\end{itemize}
\item kind of ad hoc.
\item for the uniform distribution, we have \emph{all} of the moments
         defined\ldots{} should we calculate the first $p$ moments and
         average all of them?
\begin{itemize}
\item how do we pick $p$?
\item are some moments better than others?
\end{itemize}
\end{itemize}
\end{itemize}

\section{GMM}

\begin{itemize}
\item Hansen (1982) shows that a modification of the method of
         moments can be very useful in macro:
\begin{itemize}
\item have periods $t=1,\dots,T$
\item macro models tell you that $E_t g(X_t, \theta) = 0$ where
           $g(x_t, \theta)$ is coming from Euler equations (ie, an
           agent is optimizing in period $t$, and $g$ captures the
           difference between what they expect to happen in period
           $t+1$ and what actually happens in period $t+1$ -- under
           rationality, they choose an action that makes that
           difference unpredictable.
\item LIE tells you that $E g(X_t, \theta) = E E_t g(X_t,\theta)$
           which equals zero, so you have the condition
           \[E g(X_t, \theta) = 0\]
\item Hansen shows that you can often estimate $\theta$ by solving
           \[ T^{-1} \sum_{t=1}^T g(X_t,\theta) = 0 \]
           for $\theta$. (and says how)
\item when you have more moments than parameters, gives a
           weighting scheme.
\end{itemize}
\end{itemize}

\section{Introduction to Maximum Likelihood Estimation}

\begin{itemize}
\item look at the uniform$(0,b)$ example suppose $n = 1$
\begin{itemize}
\item draw these densities for b = 1, 2, 4
\begin{itemize}
\item density is $1/b$ in $[0,b]$.
\item pick a point $x$ on the density
\end{itemize}
\item have (as a function of $b$) $1/b$ as long as $b \geq x$
\item if we observe $X = 0.5$ (for example), we know that $b \geq 0.5$
\item In addition, values like $b = 500$ are implausible
\begin{itemize}
\item as $b$ gets larger, there are more possible values that $X$ is
         likely to take on.
\end{itemize}
\item in a sense, $b = 0.5$ is the most plausible
\begin{itemize}
\item smaller values are impossible
\item as $b$ increases from $0.5$, the plausiblity decreases.
\end{itemize}
\item we can get $b = 0.5$ directly by maximizing $f(0.5; b)$ as a
       function of $b$
\begin{itemize}
\item called the likelihood and written $L(b; x)$
\end{itemize}
\end{itemize}
\end{itemize}

\section{Definition}

\begin{itemize}
\item for the MLE estimator, we start with the density, but view it as a
     function of $\theta$
\begin{itemize}
\item the value of $\theta$ that maximizes the likelihood is (in a sense) the most plausible/defensible value.
\end{itemize}
\item the MLE of $\theta$ is $argmax_\theta L(\theta; x_1,\dots,x_n)$
\end{itemize}

\section{Examples}

\subsection{iid draws from uniform$(a,b)$}
\begin{itemize}
\item $L(a,b; x_1,\dots,x_n) = \prod_i 1\{x_i \in [a,b]\} (b-a)^{-1}$
\item $= ({1 \over b-a})^{n}$ if all $x_i \in [a,b]$ and zero otherwise.
\item we can find the maximum easily
\begin{itemize}
\item likelihood decreases as $b$ increases or $a$ decreases
\item likelihood becomes zero if $b < \max x_i$ or if $a > \min x_i$
\item so $\hat b = \max x_i$ and $\hat a = \min x_i$
\end{itemize}
\end{itemize}

\subsection{linear regression.}
\begin{itemize}
\item $(Y_i,X_i) \sim iid$
\begin{itemize}
\item $X_i \sim f$ which is unspecified, $X_i$ is a $k\times1$ vector.
\item $Y_i \mid X_i \sim N(X_i'\beta, \sigma^2)$
\end{itemize}
\item want to estimate $\beta$ and $\sigma^2$
\item Draw fitted values, densities
\item $L(\mu,\sigma^2; y, x) = \prod_i {1 \over \sqrt{2 \pi \sigma^2}} e^{- {(y_i - x_i'\beta)^2 \over 2 \sigma^2}} f(x_i)$
\item step 1: take logs:
\begin{itemize}
\item $\log L(\mu,\sigma^2; x_1,\dots,x_n) = const - n\log
         (\sqrt{\sigma^2}) - \sum_i {(x_i - \mu)^2 \over 2 \sigma^2} + \sum_i f(x_i)$
\end{itemize}
\item First order conditions:
\begin{itemize}
\item for mean:
\begin{itemize}
\item $\frac{\partial}{\partial \beta} \log L(\mu, \sigma^2; x, y) = \sum_{i=1}^n x_i (y_i - x_i'\beta) = 0$
\item so $\hat\beta=(\sum_i x_i x_i')^{-1} \sum_i x_i y_i$
\end{itemize}
\item for variance:
\begin{itemize}
\item $\frac{\partial}{\partial \sigma^2} \log L(\mu, \sigma^2; x, y) = -\frac{n}{2\sigma^2} + \frac{1}{2 \sigma^4}\sum_i (y_i - x_i'\beta)^2 = 0$
\item so $\hat\sigma^2 = \frac{1}{n} \sum_{i=1}^n (y_i - x_i'\beta)^2$
\end{itemize}
\end{itemize}
\item students should verify that this is a maximum on their own.
\end{itemize}

\section{More remarks on mle}

\begin{itemize}
\item unlike method of moments, where we connect our parameters to
      the mean, variance, etc. regardless of the distribution; here
      we look at the features of the data that the distribution tells
      us are the most relevant.
\begin{itemize}
\item for normal, this \emph{is} the mean and variance, so MLE
        and MoM give us the same statistics
\item for uniform, and others, this is \emph{not} the mean and
        variance.     - the derivative of the log likelihood is called the \emph{score}.
        $S(\theta; x) = {\partial \over \partial \theta} \log L(\theta; x)$
\end{itemize}
\item has a nice invariance property: say you're not interested in the
      parameters per se, but care about a transformation of the
      parameters $T(\theta)$.  If $\hat \theta$ is the maximum
      likelihood estimator of $\theta$, then $T(\hat\theta)$ is the MLE
      of $T(\theta)$.
\item we'll see later that you can use MLE to get an estimator, even if
      you don't believe that the distribution is true
\begin{itemize}
\item called quasi-maximum likelihood
\item obviously, you then need to check that the estimator works well.
\end{itemize}
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../finitesample"
%%% End: 
